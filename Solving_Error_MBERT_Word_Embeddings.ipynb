{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Solving Error - MBERT Word Embeddings",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LollipopGB/EA_TechnicalTest_DanielGarcia/blob/master/Solving_Error_MBERT_Word_Embeddings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2IjSWx7-O8yY",
        "colab_type": "text"
      },
      "source": [
        "# MBERT Word Embeddings\n",
        "This notebook has been written following the specifications in:\n",
        "- See BERT on TensorHub: https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ytG66XXK7Sl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "06ff303a-25ef-42a1-f6a3-3a9f91123017"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Iwew0KP8vRM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a04aa3e5-fcf4-4516-acc0-6bde6fdc721d"
      },
      "source": [
        "!pip install tensorflow==2.0\n",
        "!pip install tensorflow_hub\n",
        "!pip install bert-for-tf2\n",
        "!pip install sentencepiece"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/46/0f/7bd55361168bb32796b360ad15a25de6966c9c1beb58a8e30c01c8279862/tensorflow-2.0.0-cp36-cp36m-manylinux2010_x86_64.whl (86.3MB)\n",
            "\u001b[K     |████████████████████████████████| 86.3MB 52kB/s \n",
            "\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (3.3.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (1.12.1)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (1.1.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (1.1.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (1.31.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (1.15.0)\n",
            "Collecting tensorboard<2.1.0,>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/76/54/99b9d5d52d5cb732f099baaaf7740403e83fe6b0cedde940fabd2b13d75a/tensorboard-2.0.2-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 47.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (0.35.1)\n",
            "Collecting keras-applications>=1.0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.5MB/s \n",
            "\u001b[?25hCollecting tensorflow-estimator<2.1.0,>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fc/08/8b927337b7019c374719145d1dceba21a8bb909b93b1ad6f8fb7d22c1ca1/tensorflow_estimator-2.0.1-py2.py3-none-any.whl (449kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 42.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (1.18.5)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (3.12.4)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (0.8.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (0.8.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0) (0.2.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (2.23.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (49.6.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (0.4.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (3.2.2)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (1.17.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==2.0) (2.10.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (1.24.3)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (1.7.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (4.6)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (4.1.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (0.2.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (3.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (3.1.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (0.4.8)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7542 sha256=978c9f62dd92c2523eb78ef0221b6e25a00a6aac79cf95e4d2acab9b482594a4\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "Successfully built gast\n",
            "\u001b[31mERROR: tensorflow-probability 0.11.0 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "Installing collected packages: gast, tensorboard, keras-applications, tensorflow-estimator, tensorflow\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "  Found existing installation: tensorboard 2.3.0\n",
            "    Uninstalling tensorboard-2.3.0:\n",
            "      Successfully uninstalled tensorboard-2.3.0\n",
            "  Found existing installation: tensorflow-estimator 2.3.0\n",
            "    Uninstalling tensorflow-estimator-2.3.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.3.0\n",
            "  Found existing installation: tensorflow 2.3.0\n",
            "    Uninstalling tensorflow-2.3.0:\n",
            "      Successfully uninstalled tensorflow-2.3.0\n",
            "Successfully installed gast-0.2.2 keras-applications-1.0.8 tensorboard-2.0.2 tensorflow-2.0.0 tensorflow-estimator-2.0.1\n",
            "Requirement already satisfied: tensorflow_hub in /usr/local/lib/python3.6/dist-packages (0.9.0)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow_hub) (3.12.4)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow_hub) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow_hub) (1.18.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorflow_hub) (49.6.0)\n",
            "Collecting bert-for-tf2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/87/df/ab6d927d6162657f30eb0ae3c534c723c28c191a9caf6ee68ec935df3d0b/bert-for-tf2-0.14.5.tar.gz (40kB)\n",
            "\u001b[K     |████████████████████████████████| 40kB 1.5MB/s \n",
            "\u001b[?25hCollecting py-params>=0.9.6\n",
            "  Downloading https://files.pythonhosted.org/packages/a4/bf/c1c70d5315a8677310ea10a41cfc41c5970d9b37c31f9c90d4ab98021fd1/py-params-0.9.7.tar.gz\n",
            "Collecting params-flow>=0.8.0\n",
            "  Downloading https://files.pythonhosted.org/packages/a9/95/ff49f5ebd501f142a6f0aaf42bcfd1c192dc54909d1d9eb84ab031d46056/params-flow-0.8.2.tar.gz\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (1.18.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (4.41.1)\n",
            "Building wheels for collected packages: bert-for-tf2, py-params, params-flow\n",
            "  Building wheel for bert-for-tf2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bert-for-tf2: filename=bert_for_tf2-0.14.5-cp36-none-any.whl size=30317 sha256=8750b963d00a5d43dfa2501e9a586902fea867797bed6fc61f00b278a1d50335\n",
            "  Stored in directory: /root/.cache/pip/wheels/2e/70/a2/be357037dd2cbdcaeb0add1fdf083be6a600ca65ee1f68751c\n",
            "  Building wheel for py-params (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for py-params: filename=py_params-0.9.7-cp36-none-any.whl size=7304 sha256=3c5eecc4549607b77d6c3ecb503a23dde01cead12de69059ddf83a07b1e72d85\n",
            "  Stored in directory: /root/.cache/pip/wheels/67/f5/19/b461849a50aefdf4bab47c4756596e82ee2118b8278e5a1980\n",
            "  Building wheel for params-flow (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for params-flow: filename=params_flow-0.8.2-cp36-none-any.whl size=19475 sha256=9e6bcaf031f2549f2b0469f27122c95280518b8ed1eec9b180ab35e11bafd4ad\n",
            "  Stored in directory: /root/.cache/pip/wheels/08/c8/7f/81c86b9ff2b86e2c477e3914175be03e679e596067dc630c06\n",
            "Successfully built bert-for-tf2 py-params params-flow\n",
            "Installing collected packages: py-params, params-flow, bert-for-tf2\n",
            "Successfully installed bert-for-tf2-0.14.5 params-flow-0.8.2 py-params-0.9.7\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 3.5MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.91\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NV-yr9ulP_E-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "6f10034b-fc8f-4f25-ee96-62c19d91a8a2"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "print(\"TF version: \", tf.__version__)\n",
        "print(\"Hub version: \", hub.__version__)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TF version:  2.0.0\n",
            "Hub version:  0.9.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cMeXU54uQUew",
        "colab_type": "text"
      },
      "source": [
        "## Import modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBfktvAc-CNb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow_hub as hub\n",
        "import tensorflow as tf\n",
        "import bert\n",
        "FullTokenizer = bert.bert_tokenization.FullTokenizer\n",
        "from tensorflow.keras.models import Model       # Keras is the new high level API for TensorFlow\n",
        "import math\n",
        "import pandas as pd\n",
        "import string"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mx_VBx2LLNxV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = '/content/drive/My Drive/ea_corpora_no_nan.csv'\n",
        "df = pd.read_csv(path, sep=',', header=0)\n",
        "max_seq_length = 128"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tU2OpvYrRFNf",
        "colab_type": "text"
      },
      "source": [
        "## Building the model\n",
        "\n",
        "Building model using tf.keras and hub. from sentences to embeddings.\n",
        "\n",
        "Inputs:\n",
        " - input token ids (tokenizer converts tokens using vocab file)\n",
        " - input masks (1 for useful tokens, 0 for padding)\n",
        " - segment ids (for 2 text training: 0 for the first one, 1 for the second one)\n",
        "\n",
        "Outputs:\n",
        " - pooled_output of shape `[batch_size, 768]` with representations for the entire input sequences\n",
        " - sequence_output of shape `[batch_size, max_seq_length, 768]` with representations for each input token (in context)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IW6V3afD-q1K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_word_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32,\n",
        "                                       name=\"input_word_ids\")\n",
        "input_mask = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32,\n",
        "                                   name=\"input_mask\")\n",
        "segment_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32,\n",
        "                                    name=\"segment_ids\")\n",
        "bert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/2\",\n",
        "                            trainable=False)\n",
        "pooled_output, sequence_output = bert_layer([input_word_ids, input_mask, segment_ids])"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gmR3jHYE_y3X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Model(inputs=[input_word_ids, input_mask, segment_ids], outputs=[pooled_output, sequence_output])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CiZCX3KMkgJa",
        "colab_type": "text"
      },
      "source": [
        "## Example of generating an embedding\n",
        "\n",
        "First, we preprocessed the sentence following the BERT methodology. Then, we generate the ids, mask and segments with the tokenizer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sm3lGfQb-1J8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
        "do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
        "tokenizer = FullTokenizer(vocab_file, do_lower_case)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jVkTaR0lCcCM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "s = \"This nice, sentence.\""
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AihvrFWcSzd6",
        "colab_type": "text"
      },
      "source": [
        "Tokenizing the sentence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X798BKV_Co71",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stokens = tokenizer.tokenize(s)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PxroAvbjStsX",
        "colab_type": "text"
      },
      "source": [
        "Adding separator tokens according to the paper"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "znzQLHURDAfs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stokens = [\"[CLS]\"] + stokens + [\"[SEP]\"]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kRwyPuauTc2z",
        "colab_type": "text"
      },
      "source": [
        "Get the model inputs from the tokens"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PyyjWY75Flns",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_ids = get_ids(stokens, tokenizer, max_seq_length)\n",
        "input_masks = get_masks(stokens, max_seq_length)\n",
        "input_segments = get_segments(stokens, max_seq_length)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FgKzlBloMX_Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "283b827f-8a94-4d99-f62e-a8af0289a7bd"
      },
      "source": [
        "print(stokens)\n",
        "print(input_ids)\n",
        "print(input_masks)\n",
        "print(input_segments)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['[CLS]', 'This', 'nic', '##e', ',', 'sentence', '.', '[SEP]']\n",
            "[101, 10747, 46267, 10112, 117, 49219, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mi2mj4EUTi0X",
        "colab_type": "text"
      },
      "source": [
        "Generate Embeddings using the pretrained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ik3xqHqXM_lN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pool_embs, all_embs = model.predict([[input_ids],[input_masks],[input_segments]])"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3TUVuKEnKP2L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5075e518-5845-4a82-b5cc-a8bd56b20248"
      },
      "source": [
        "pool_embs"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.23276514, -0.00594373,  0.30834806, -0.20356625, -0.09590112,\n",
              "         0.43650317,  0.2871416 ,  0.30860618, -0.4822504 ,  0.36143574,\n",
              "         0.05642665, -0.32627806, -0.24309899, -0.09139016,  0.16354893,\n",
              "        -0.23851739,  0.7306353 ,  0.03081608,  0.04861095, -0.30492905,\n",
              "        -0.9998869 , -0.2516094 , -0.20149425, -0.16954152, -0.44420984,\n",
              "         0.21227205, -0.3052292 ,  0.33267456,  0.26318187, -0.29790413,\n",
              "         0.22276796, -0.9998971 ,  0.55339444,  0.71306735,  0.32374546,\n",
              "        -0.17143737,  0.0824426 ,  0.28915772,  0.2440962 , -0.39900273,\n",
              "        -0.25733086, -0.05787262, -0.14064786,  0.19076537, -0.12050197,\n",
              "        -0.41198155, -0.2559957 ,  0.265201  , -0.346468  ,  0.01656516,\n",
              "         0.11038731,  0.36560035,  0.49111158,  0.2537717 ,  0.25466797,\n",
              "         0.16619101,  0.18128854,  0.24105678,  0.35735092, -0.24011606,\n",
              "        -0.02952298,  0.44282633,  0.22373076, -0.17051585, -0.2681529 ,\n",
              "        -0.3102133 ,  0.21565759, -0.02486245,  0.6128571 , -0.3708624 ,\n",
              "        -0.19007398, -0.44145504, -0.15612681,  0.07602064,  0.21699698,\n",
              "        -0.34233215,  0.37393242,  0.23175648,  0.18331352, -0.15871036,\n",
              "        -0.4316133 , -0.5652913 , -0.3450879 ,  0.27048615, -0.28526002,\n",
              "         0.4017716 ,  0.32467964, -0.42311975,  0.09447096, -0.22629261,\n",
              "         0.11773462,  0.55411935, -0.30234954,  0.33465913, -0.2317813 ,\n",
              "        -0.2766916 , -0.81390285, -0.23891991, -0.27856308, -0.41319314,\n",
              "        -0.18582925,  0.1724896 , -0.31321183, -0.36623102, -0.2971107 ,\n",
              "        -0.34692374,  0.21213232,  0.18430927, -0.12628457,  0.31443593,\n",
              "         0.14291236, -0.45243326, -0.25249028,  0.10422144, -0.32793012,\n",
              "         0.9675063 , -0.44957653,  0.3835519 , -0.00669392,  0.03161692,\n",
              "        -0.5299464 ,  0.99992347,  0.08794917, -0.170785  ,  0.20855048,\n",
              "         0.27028313, -0.5952548 ,  0.17624228,  0.461289  ,  0.3267006 ,\n",
              "         0.20332816, -0.22818011, -0.24633713, -0.30090645, -0.77897006,\n",
              "        -0.30267894, -0.25675663,  0.26036018, -0.4535266 , -0.19290702,\n",
              "         0.22660863,  0.43792728,  0.24898322,  0.02256094, -0.10999619,\n",
              "        -0.14193961,  0.26641   , -0.23075803,  0.99989897,  0.65828454,\n",
              "        -0.31302655, -0.1436186 ,  0.4630034 , -0.5298982 , -0.3889124 ,\n",
              "        -0.35383365, -0.4237447 , -0.5300141 ,  0.20408264,  0.18583134,\n",
              "         0.2607763 , -0.17009363, -0.2669954 , -0.37507564,  0.2589348 ,\n",
              "        -0.7312192 , -0.12595166,  0.44580683,  0.02963127,  0.43899646,\n",
              "        -0.26443335,  0.45226553,  0.2165475 , -0.3121    , -0.04170161,\n",
              "         0.38607436,  0.2322483 ,  0.06040393, -0.11614744, -0.09297196,\n",
              "         0.29260308, -0.13669485, -0.37017474,  0.11299584, -0.26627672,\n",
              "        -0.39766338,  0.14798994, -0.04645436, -0.13649788,  0.31028533,\n",
              "        -0.2442691 ,  0.16149564, -0.20634401,  0.31251138,  0.3242298 ,\n",
              "         0.07071055, -0.5484615 ,  0.29720137,  0.34416202,  0.34953728,\n",
              "         0.25967962,  0.1684611 ,  0.04588941,  0.22038168, -0.31704608,\n",
              "        -0.3818678 ,  0.38895074,  0.16222169,  0.4201263 , -0.26173878,\n",
              "        -0.40974176, -0.3815871 ,  0.5842721 ,  0.36358282, -0.3344921 ,\n",
              "         0.3574721 ,  0.18703862, -0.24146853, -0.3057562 ,  0.20240806,\n",
              "        -0.13920057, -0.30029202, -0.4735909 , -0.27071652, -0.1317027 ,\n",
              "         0.34965032,  0.12209401,  0.2759549 ,  0.25153944, -0.08328671,\n",
              "        -0.17778602, -0.20390505,  0.15212837,  0.27180514, -0.09372254,\n",
              "         0.8110581 , -0.09506962,  0.1667129 , -0.38458264, -0.24180295,\n",
              "         0.3031862 , -0.11198993,  0.37565917,  0.95231885,  0.18326126,\n",
              "        -0.35710505,  0.19963343,  0.30791172,  0.262507  , -0.25192237,\n",
              "         0.09890575, -0.61409295,  0.61879444,  0.3977721 ,  0.2787834 ,\n",
              "        -0.9998856 ,  0.16148333,  0.09891237,  0.38574532,  0.16806974,\n",
              "         0.1642355 ,  0.24466902,  0.22626898,  0.8983674 , -0.30796215,\n",
              "        -0.46358147, -0.29814905, -0.23738314, -0.56672245, -0.21368682,\n",
              "        -0.20955105, -0.34357285, -0.23936827, -0.00925232, -0.28343204,\n",
              "         0.3173831 ,  0.29189754, -0.98946714,  0.85463834,  0.17614171,\n",
              "        -0.28166917, -0.1045668 ,  0.22607885, -0.99990284,  0.38224185,\n",
              "        -0.05621589, -0.36887556,  0.29057366, -0.34857166, -0.32815552,\n",
              "         0.14386265,  0.39407685,  0.35441017,  0.2518847 ,  0.00163108,\n",
              "         0.60129875,  0.07605929,  0.05792092,  0.09521545, -0.06472924,\n",
              "         0.5788804 , -0.08079549,  0.197109  ,  0.32501215, -0.06902836,\n",
              "         0.3345296 , -0.2695023 ,  0.3597952 ,  0.3901044 ,  0.17764491,\n",
              "         0.07417345, -0.26692387,  0.28116804, -0.7553349 ,  0.29936954,\n",
              "        -0.05156202, -0.1579995 , -0.13797492,  0.10480367, -0.3094763 ,\n",
              "        -0.33415926,  0.28577822, -0.43496683,  0.9998925 ,  0.11532658,\n",
              "        -0.30461165, -0.3228693 ,  0.5134467 ,  0.5026132 , -0.22646539,\n",
              "        -0.5397555 , -0.1445588 ,  0.5386708 ,  0.4452949 ,  0.07905259,\n",
              "         0.21792778, -0.04455645,  0.05689631, -0.13209915, -0.25892043,\n",
              "         0.02604879, -0.3754369 ,  0.1300774 , -0.11126201, -0.45080066,\n",
              "         0.1403903 , -0.15921044, -0.11843453, -0.534337  ,  0.3106091 ,\n",
              "         0.14644027,  0.19637579,  0.13191384,  0.08798676, -0.38097778,\n",
              "         0.6478336 ,  0.35908243, -0.29269344, -0.23099774, -0.30265814,\n",
              "        -0.22672497,  0.03134594, -0.2896773 , -0.3317228 ,  0.15040326,\n",
              "        -0.6746504 ,  0.09798677, -0.13430606, -0.22551136, -0.4366074 ,\n",
              "         0.3970206 , -0.99992555, -0.08667066,  0.22346489, -0.17557195,\n",
              "         0.20384432, -0.3576832 , -0.2080844 ,  0.14041634,  0.16386172,\n",
              "         0.09233476,  0.20360482, -0.3540699 ,  0.11664802, -0.09716379,\n",
              "         0.19535215,  0.80010104,  0.5611062 ,  0.1064925 , -0.41004404,\n",
              "         0.28008708, -0.5537803 , -0.23605274,  0.42580605,  0.18952304,\n",
              "        -0.18730472,  0.19850369,  0.30337316,  0.3043316 , -0.31915736,\n",
              "         0.37632582, -0.17846964, -0.12461583,  0.31979662,  0.00813684,\n",
              "        -0.16516618, -0.33972687,  0.43466994, -0.45022592,  0.43600255,\n",
              "         0.21551949,  0.32514173,  0.07371621,  0.36932376, -0.31062344,\n",
              "        -0.17294629, -0.27547365, -0.06594077, -0.38498414, -0.30582482,\n",
              "        -0.20989914,  0.99991286,  0.27883312,  0.35662562, -0.37492955,\n",
              "         0.23762807,  0.40244195, -0.28014472,  0.28697082,  0.3841882 ,\n",
              "         0.13430785, -0.12828864,  0.18574491,  0.3656648 ,  0.3856163 ,\n",
              "         0.45906568,  0.1793911 ,  0.44848973, -0.37000948,  0.6520128 ,\n",
              "        -0.23827396, -0.42334896, -0.9904662 ,  0.22417201,  0.49513015,\n",
              "        -0.27861476, -0.5211792 ,  0.21396318, -0.3578805 ,  0.20600164,\n",
              "        -0.25524312,  0.09314397,  0.25720567, -0.22158806,  0.39646354,\n",
              "        -0.18112536,  0.9998978 , -0.05652231,  0.10126055,  0.32786587,\n",
              "         0.2805725 , -0.3447764 , -0.3438975 , -0.16547887,  0.35414127,\n",
              "        -0.32742426,  0.09875812, -0.92785966,  0.29372916,  0.09748492,\n",
              "         0.42520458, -0.20551836,  0.34150478, -0.55258435,  0.39502245,\n",
              "        -0.13672887, -0.0998479 , -0.33435646,  0.30717105, -0.39291912,\n",
              "         0.5984699 , -0.31631055,  0.20072699, -0.3182156 ,  0.24385953,\n",
              "         0.05772875,  0.41720343, -0.29344094,  0.07774721, -0.37800613,\n",
              "        -0.34886265, -0.24541871,  0.13220745, -0.46464226,  0.99990857,\n",
              "        -0.18942736,  0.39362812, -0.2227465 ,  0.28618416, -0.28473705,\n",
              "         0.5156418 ,  0.76083845, -0.31007054,  0.28388292,  0.3381882 ,\n",
              "        -0.67802477,  0.31384283, -0.03614872, -0.6269376 , -0.1295401 ,\n",
              "         0.9536599 ,  0.15305762,  0.41595635,  0.39574984,  0.17642589,\n",
              "         0.21141255, -0.26513562,  0.25370058,  0.8183471 ,  0.04853345,\n",
              "         0.18362392,  0.16860135,  0.02625354, -0.43115303, -0.28434122,\n",
              "         0.99990135,  0.99989915,  0.01749122,  0.44218892, -0.15791474,\n",
              "        -0.25986505, -0.2924746 ,  0.24307945,  0.25742444,  0.20759508,\n",
              "        -0.00615307,  0.11124914, -0.43280506, -0.25150228, -0.24398004,\n",
              "        -0.08365053, -0.22427478, -0.01680108, -0.42616543,  0.6961741 ,\n",
              "         0.47195873,  0.20366538,  0.4456487 ,  0.24817178,  0.24504966,\n",
              "         0.04909996, -0.34006992,  0.58742005, -0.36885592, -0.00693787,\n",
              "        -0.36495435,  0.07550748, -0.99989134, -0.31741065, -0.18587033,\n",
              "        -0.30533233,  0.5690084 ,  0.11681611,  0.12572095, -0.43683967,\n",
              "        -0.1360066 , -0.44179478,  0.23985173,  0.2529134 ,  0.1845553 ,\n",
              "        -0.24756156, -0.3199127 ,  0.47458512, -0.45381328,  0.14189284,\n",
              "        -0.23979829, -0.3768954 , -0.59939086, -0.2645166 , -0.34338313,\n",
              "         0.35119832, -0.07649539, -0.20391269,  0.37876204,  0.1777754 ,\n",
              "         0.37507036, -0.34225446,  0.31888163, -0.25976193,  0.20031884,\n",
              "         0.38243946,  0.28480074,  0.20082933, -0.4091426 , -0.34152013,\n",
              "        -0.29605034, -0.24640898, -0.3287544 ,  0.33354783, -0.3353891 ,\n",
              "         0.2753487 , -0.15926391,  0.13114779, -0.17099619,  0.1436927 ,\n",
              "         0.26066032,  0.5304651 , -0.24824302,  0.44981134,  0.47258204,\n",
              "        -0.13576947,  0.5895198 ,  0.04134218, -0.26113474, -0.26663306,\n",
              "         0.99991417,  0.3266463 ,  0.1447812 ,  0.22322144,  0.03879426,\n",
              "         0.38921925,  0.22774081,  0.56968206, -0.2093468 ,  0.6106745 ,\n",
              "        -0.28780246,  0.2418115 ,  0.25196508,  0.4347364 , -0.00799005,\n",
              "         0.25860813,  0.21135958,  0.7619346 ,  0.27418885,  0.21308488,\n",
              "         0.37789217,  0.24713016,  0.47257876,  0.18314466,  0.16149445,\n",
              "         0.389441  ,  0.28325477, -0.1427634 ,  0.19403955, -0.21395832,\n",
              "        -0.21994685, -0.09832633, -0.12532948, -0.22294594,  0.05310789,\n",
              "        -0.03240652, -0.27738395, -0.18215892,  0.4229388 , -0.31769872,\n",
              "         0.22885601, -0.26264182, -0.2507752 ,  0.49780607, -0.53328496,\n",
              "         0.42485902, -0.09513958,  0.23984279, -0.7744864 ,  0.24086805,\n",
              "        -0.10698932, -0.55117595, -0.27106267, -0.35973284,  0.18706988,\n",
              "         0.3371058 , -0.12735495,  0.21064936, -0.19676729,  0.38389468,\n",
              "        -0.16345565, -0.29221988,  0.077038  , -0.9999059 ,  0.18927923,\n",
              "         0.15395321, -0.42033604,  0.1781054 , -0.03868948,  0.23854479,\n",
              "         0.2846328 , -0.32163844, -0.36325812, -0.15054134,  0.22699998,\n",
              "        -0.36290178, -0.03572591,  0.24494977, -0.39396518, -0.31060562,\n",
              "         0.19197695, -0.297014  ,  0.34834477,  0.45707318, -0.3375331 ,\n",
              "         0.27413735, -0.2801785 ,  0.16591473, -0.15394115,  0.18194102,\n",
              "        -0.40903455, -0.29716712,  0.43307585, -0.40217823, -0.40231174,\n",
              "        -0.23153803,  0.17705086, -0.08659513,  0.1497613 ,  0.3417415 ,\n",
              "        -0.08103021,  0.3525509 , -0.2138921 ,  0.38600898, -0.16485994,\n",
              "         0.3976869 , -0.8344107 , -0.31874081, -0.43804777, -0.17348517,\n",
              "         0.22131385,  0.3893119 ,  0.13410102,  0.2427439 ,  0.00525909,\n",
              "         0.3059484 , -0.07604603,  0.25236118,  0.29572323, -0.3385049 ,\n",
              "         0.05501411, -0.38461074,  0.263361  , -0.4219868 ,  0.0479254 ,\n",
              "        -0.98042977, -0.33324692,  0.13642   ,  0.36830816,  0.3327452 ,\n",
              "        -0.33907464, -0.09718073, -0.40090066, -0.24229006,  0.2606372 ,\n",
              "         0.09241854,  0.30592203,  0.32254168,  0.38963053, -0.190012  ,\n",
              "         0.0456745 ,  0.6154998 , -0.29435018,  0.05119732,  0.46237716,\n",
              "         0.42341867,  0.6922996 ,  0.36411852,  0.38114172,  0.17765826,\n",
              "        -0.2165645 ,  0.39966458,  0.3762282 ]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_Tj5vj8lDoq",
        "colab_type": "text"
      },
      "source": [
        "## Generate the dataset\n",
        "\n",
        "Define auxiliar methods to generate the batches to obtain the word embeddings per document.\n",
        "\n",
        "At the beginning, the documents were trim to 1000 words (the 3rd quartile of number of documents per total size) to generate small number of batches per document without losing too much information. However, it was going to take about 17 hours to generate all the embeddings, so just to show the whole process and reduce computational time as que are not seeking the best performance and quality, the texts are greatly reduced to 100 words. The execution time was still 6 hours. So, we are going to reduce the dataset length, **just to show the process with the classifier**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPbLhtylL_xo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def reduce_text(text):\n",
        "  if len(text.split()) > 100:\n",
        "    return \" \".join(text.split()[:100])\n",
        "  else:\n",
        "    return text\n",
        "\n",
        "def get_masks(tokens, max_seq_length):\n",
        "    \"\"\"Mask for padding\"\"\"\n",
        "    if len(tokens)>max_seq_length:\n",
        "        raise IndexError(\"Token length more than max seq length!\")\n",
        "    return [1]*len(tokens) + [0] * (max_seq_length - len(tokens))\n",
        "\n",
        "\n",
        "def get_segments(tokens, max_seq_length):\n",
        "    \"\"\"Segments: 0 for the first sequence, 1 for the second\"\"\"\n",
        "    if len(tokens)>max_seq_length:\n",
        "        raise IndexError(\"Token length more than max seq length!\")\n",
        "    segments = []\n",
        "    current_segment_id = 0\n",
        "    for token in tokens:\n",
        "        segments.append(current_segment_id)\n",
        "        if token == \"[SEP]\":\n",
        "            current_segment_id = 1\n",
        "    return segments + [0] * (max_seq_length - len(tokens))\n",
        "\n",
        "\n",
        "def get_ids(tokens, tokenizer, max_seq_length):\n",
        "    \"\"\"Token ids from Tokenizer vocab\"\"\"\n",
        "    token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "    input_ids = token_ids + [0] * (max_seq_length-len(token_ids))\n",
        "    return input_ids\n",
        "\n",
        "def generate_batches(text, size):\n",
        "  chunks = [text[x:x+size] for x in range(0, len(text), size)]\n",
        "  for c in chunks:\n",
        "    c.insert(0, '[CLS]')\n",
        "    c.append('[SEP]')\n",
        "  return chunks\n",
        "\n",
        "def generate_all(row):\n",
        "  data_prepared = []\n",
        "  for i in row:\n",
        "    input_ids = get_ids(i, tokenizer, max_seq_length)\n",
        "    input_masks = get_masks(i, max_seq_length)\n",
        "    input_segments = get_segments(i, max_seq_length)\n",
        "    data_prepared.append([input_ids, input_masks, input_segments])\n",
        "  return data_prepared\n",
        "\n",
        "def get_embeddings(batches):\n",
        "  embedding = []\n",
        "  for batch in batches:\n",
        "    pool_embs, all_embs = model.predict([[batch[0]], [batch[1]], [batch[2]]])\n",
        "    embedding.append(pool_embs)\n",
        "  return embedding"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WnUqdly8_MTI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_reduced = df.iloc[range(0,len(df),3)]\n",
        "df_reduced = df_reduced.reset_index()"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGZzycVv_P7l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ff6602d2-34cb-43ae-cbc0-e9d03703a31d"
      },
      "source": [
        "df_reduced.shape"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7847, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "et4LbS-qLVEX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_reduced['text_reduced'] = df_reduced['text'].apply(lambda x: reduce_text(x))"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W5YIOEcqMuhn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_reduced['text_tokens'] = df_reduced['text_reduced'].apply(lambda x: tokenizer.tokenize(x))"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hAlIPVM1RSZ0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_reduced['text_batches'] = df_reduced['text_tokens'].apply(lambda x: generate_batches(x, 100))"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oa7qJUbcdp1D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_reduced['basic_set'] = df_reduced['text_batches'].apply(lambda x: generate_all(x))"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-E55I-kaZyWX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "e6410520-0940-434d-a873-3839bbdc5bbf"
      },
      "source": [
        "df_reduced.head()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>text</th>\n",
              "      <th>category</th>\n",
              "      <th>language</th>\n",
              "      <th>text_reduced</th>\n",
              "      <th>text_tokens</th>\n",
              "      <th>text_batches</th>\n",
              "      <th>basic_set</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>i read this book because in my town, everyone ...</td>\n",
              "      <td>APR</td>\n",
              "      <td>en</td>\n",
              "      <td>i read this book because in my town, everyone ...</td>\n",
              "      <td>[i, read, this, book, because, in, my, town, ,...</td>\n",
              "      <td>[[[CLS], i, read, this, book, because, in, my,...</td>\n",
              "      <td>[[[101, 177, 24944, 10531, 12748, 12373, 10106...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>milady has found a good vein: anita blake. bas...</td>\n",
              "      <td>APR</td>\n",
              "      <td>en</td>\n",
              "      <td>milady has found a good vein: anita blake. bas...</td>\n",
              "      <td>[mil, ##ady, has, found, a, good, vei, ##n, :,...</td>\n",
              "      <td>[[[CLS], mil, ##ady, has, found, a, good, vei,...</td>\n",
              "      <td>[[[101, 15033, 51210, 10393, 11823, 169, 15198...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6</td>\n",
              "      <td>well, frankly, the first 3 volumes of the new ...</td>\n",
              "      <td>APR</td>\n",
              "      <td>en</td>\n",
              "      <td>well, frankly, the first 3 volumes of the new ...</td>\n",
              "      <td>[well, ,, fra, ##nk, ##ly, ,, the, first, 3, v...</td>\n",
              "      <td>[[[CLS], well, ,, fra, ##nk, ##ly, ,, the, fir...</td>\n",
              "      <td>[[[101, 11206, 117, 10628, 17761, 10454, 117, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9</td>\n",
              "      <td>it is a deafening silence olivier delorme brea...</td>\n",
              "      <td>APR</td>\n",
              "      <td>en</td>\n",
              "      <td>it is a deafening silence olivier delorme brea...</td>\n",
              "      <td>[it, is, a, dea, ##fen, ##ing, silence, oli, #...</td>\n",
              "      <td>[[[CLS], it, is, a, dea, ##fen, ##ing, silence...</td>\n",
              "      <td>[[[101, 10271, 10124, 169, 42492, 15559, 10230...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>12</td>\n",
              "      <td>i really like if it was true, and i felt faint...</td>\n",
              "      <td>APR</td>\n",
              "      <td>en</td>\n",
              "      <td>i really like if it was true, and i felt faint...</td>\n",
              "      <td>[i, really, like, if, it, was, true, ,, and, i...</td>\n",
              "      <td>[[[CLS], i, really, like, if, it, was, true, ,...</td>\n",
              "      <td>[[[101, 177, 30181, 11850, 12277, 10271, 10134...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   index  ...                                          basic_set\n",
              "0      0  ...  [[[101, 177, 24944, 10531, 12748, 12373, 10106...\n",
              "1      3  ...  [[[101, 15033, 51210, 10393, 11823, 169, 15198...\n",
              "2      6  ...  [[[101, 11206, 117, 10628, 17761, 10454, 117, ...\n",
              "3      9  ...  [[[101, 10271, 10124, 169, 42492, 15559, 10230...\n",
              "4     12  ...  [[[101, 177, 30181, 11850, 12277, 10271, 10134...\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FbpqCnC26VLv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tqdm import tqdm"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A45i5B0Jdp7P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2061eec8-5d36-4378-aef7-7a8cbf6951ac"
      },
      "source": [
        "tqdm.pandas()\n",
        "df_reduced['embeddings'] = df_reduced['basic_set'].progress_apply(lambda x: get_embeddings(x))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 7847/7847 [3:47:15<00:00,  1.74s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJHzR-hWoY9n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "7e348338-6de6-419b-e9da-079f0cba3bd3"
      },
      "source": [
        "df_reduced.head()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>text</th>\n",
              "      <th>category</th>\n",
              "      <th>language</th>\n",
              "      <th>text_reduced</th>\n",
              "      <th>text_tokens</th>\n",
              "      <th>text_batches</th>\n",
              "      <th>basic_set</th>\n",
              "      <th>embeddings</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>i read this book because in my town, everyone ...</td>\n",
              "      <td>APR</td>\n",
              "      <td>en</td>\n",
              "      <td>i read this book because in my town, everyone ...</td>\n",
              "      <td>[i, read, this, book, because, in, my, town, ,...</td>\n",
              "      <td>[[[CLS], i, read, this, book, because, in, my,...</td>\n",
              "      <td>[[[101, 177, 24944, 10531, 12748, 12373, 10106...</td>\n",
              "      <td>[[[0.21412727, -0.25563636, 0.3922883, -0.1099...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>milady has found a good vein: anita blake. bas...</td>\n",
              "      <td>APR</td>\n",
              "      <td>en</td>\n",
              "      <td>milady has found a good vein: anita blake. bas...</td>\n",
              "      <td>[mil, ##ady, has, found, a, good, vei, ##n, :,...</td>\n",
              "      <td>[[[CLS], mil, ##ady, has, found, a, good, vei,...</td>\n",
              "      <td>[[[101, 15033, 51210, 10393, 11823, 169, 15198...</td>\n",
              "      <td>[[[0.21550941, -0.32545748, 0.33222845, -0.287...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6</td>\n",
              "      <td>well, frankly, the first 3 volumes of the new ...</td>\n",
              "      <td>APR</td>\n",
              "      <td>en</td>\n",
              "      <td>well, frankly, the first 3 volumes of the new ...</td>\n",
              "      <td>[well, ,, fra, ##nk, ##ly, ,, the, first, 3, v...</td>\n",
              "      <td>[[[CLS], well, ,, fra, ##nk, ##ly, ,, the, fir...</td>\n",
              "      <td>[[[101, 11206, 117, 10628, 17761, 10454, 117, ...</td>\n",
              "      <td>[[[0.026787607, -0.3051752, 0.072571024, -0.58...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9</td>\n",
              "      <td>it is a deafening silence olivier delorme brea...</td>\n",
              "      <td>APR</td>\n",
              "      <td>en</td>\n",
              "      <td>it is a deafening silence olivier delorme brea...</td>\n",
              "      <td>[it, is, a, dea, ##fen, ##ing, silence, oli, #...</td>\n",
              "      <td>[[[CLS], it, is, a, dea, ##fen, ##ing, silence...</td>\n",
              "      <td>[[[101, 10271, 10124, 169, 42492, 15559, 10230...</td>\n",
              "      <td>[[[0.16710715, -0.19441627, 0.23410313, -0.311...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>12</td>\n",
              "      <td>i really like if it was true, and i felt faint...</td>\n",
              "      <td>APR</td>\n",
              "      <td>en</td>\n",
              "      <td>i really like if it was true, and i felt faint...</td>\n",
              "      <td>[i, really, like, if, it, was, true, ,, and, i...</td>\n",
              "      <td>[[[CLS], i, really, like, if, it, was, true, ,...</td>\n",
              "      <td>[[[101, 177, 30181, 11850, 12277, 10271, 10134...</td>\n",
              "      <td>[[[0.3504453, -0.23025343, 0.31962156, -0.2193...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   index  ...                                         embeddings\n",
              "0      0  ...  [[[0.21412727, -0.25563636, 0.3922883, -0.1099...\n",
              "1      3  ...  [[[0.21550941, -0.32545748, 0.33222845, -0.287...\n",
              "2      6  ...  [[[0.026787607, -0.3051752, 0.072571024, -0.58...\n",
              "3      9  ...  [[[0.16710715, -0.19441627, 0.23410313, -0.311...\n",
              "4     12  ...  [[[0.3504453, -0.23025343, 0.31962156, -0.2193...\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hp2d_2kvGBf8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_final = df_reduced.drop(columns=['text_reduced', 'text_tokens', 'text', 'text_batches', 'basic_set', 'index'])"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PP4k5fTTGMfj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "ffe70ee6-f083-4a7e-d02d-27bf3841c6a4"
      },
      "source": [
        "df_final.head()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>language</th>\n",
              "      <th>embeddings</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>APR</td>\n",
              "      <td>en</td>\n",
              "      <td>[[[0.21412727, -0.25563636, 0.3922883, -0.1099...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>APR</td>\n",
              "      <td>en</td>\n",
              "      <td>[[[0.21550941, -0.32545748, 0.33222845, -0.287...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>APR</td>\n",
              "      <td>en</td>\n",
              "      <td>[[[0.026787607, -0.3051752, 0.072571024, -0.58...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>APR</td>\n",
              "      <td>en</td>\n",
              "      <td>[[[0.16710715, -0.19441627, 0.23410313, -0.311...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>APR</td>\n",
              "      <td>en</td>\n",
              "      <td>[[[0.3504453, -0.23025343, 0.31962156, -0.2193...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  category language                                         embeddings\n",
              "0      APR       en  [[[0.21412727, -0.25563636, 0.3922883, -0.1099...\n",
              "1      APR       en  [[[0.21550941, -0.32545748, 0.33222845, -0.287...\n",
              "2      APR       en  [[[0.026787607, -0.3051752, 0.072571024, -0.58...\n",
              "3      APR       en  [[[0.16710715, -0.19441627, 0.23410313, -0.311...\n",
              "4      APR       en  [[[0.3504453, -0.23025343, 0.31962156, -0.2193..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9JKOs0VqzYvV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = []\n",
        "\n",
        "for i in range(len(df_final)):\n",
        "\n",
        "  new_row = [item for sublist in df_final.loc[i]['embeddings'] for item in sublist.tolist()[0]]\n",
        "\n",
        "  new_row.insert(0, df_final.loc[i]['category'])\n",
        "  new_row.insert(0, df_final.loc[i]['language'])\n",
        "  data.append(new_row)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-Elc0Zvp6Ib",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_flatten = pd.DataFrame(data)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9FeMqIApTo7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "outputId": "107d464f-54dd-4ea2-af57-4321990f49cd"
      },
      "source": [
        "df_flatten.head()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>6874</th>\n",
              "      <th>6875</th>\n",
              "      <th>6876</th>\n",
              "      <th>6877</th>\n",
              "      <th>6878</th>\n",
              "      <th>6879</th>\n",
              "      <th>6880</th>\n",
              "      <th>6881</th>\n",
              "      <th>6882</th>\n",
              "      <th>6883</th>\n",
              "      <th>6884</th>\n",
              "      <th>6885</th>\n",
              "      <th>6886</th>\n",
              "      <th>6887</th>\n",
              "      <th>6888</th>\n",
              "      <th>6889</th>\n",
              "      <th>6890</th>\n",
              "      <th>6891</th>\n",
              "      <th>6892</th>\n",
              "      <th>6893</th>\n",
              "      <th>6894</th>\n",
              "      <th>6895</th>\n",
              "      <th>6896</th>\n",
              "      <th>6897</th>\n",
              "      <th>6898</th>\n",
              "      <th>6899</th>\n",
              "      <th>6900</th>\n",
              "      <th>6901</th>\n",
              "      <th>6902</th>\n",
              "      <th>6903</th>\n",
              "      <th>6904</th>\n",
              "      <th>6905</th>\n",
              "      <th>6906</th>\n",
              "      <th>6907</th>\n",
              "      <th>6908</th>\n",
              "      <th>6909</th>\n",
              "      <th>6910</th>\n",
              "      <th>6911</th>\n",
              "      <th>6912</th>\n",
              "      <th>6913</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>en</td>\n",
              "      <td>APR</td>\n",
              "      <td>0.214127</td>\n",
              "      <td>-0.255636</td>\n",
              "      <td>0.392288</td>\n",
              "      <td>-0.109920</td>\n",
              "      <td>-0.026097</td>\n",
              "      <td>0.148366</td>\n",
              "      <td>0.293664</td>\n",
              "      <td>0.275959</td>\n",
              "      <td>-0.319734</td>\n",
              "      <td>0.139019</td>\n",
              "      <td>-0.054376</td>\n",
              "      <td>0.000006</td>\n",
              "      <td>-0.180775</td>\n",
              "      <td>-0.144149</td>\n",
              "      <td>0.103221</td>\n",
              "      <td>-0.070089</td>\n",
              "      <td>0.368038</td>\n",
              "      <td>0.070929</td>\n",
              "      <td>0.201238</td>\n",
              "      <td>-0.079317</td>\n",
              "      <td>-0.999311</td>\n",
              "      <td>-0.197135</td>\n",
              "      <td>-0.162490</td>\n",
              "      <td>-0.111980</td>\n",
              "      <td>-0.295185</td>\n",
              "      <td>0.138431</td>\n",
              "      <td>-0.152204</td>\n",
              "      <td>0.292405</td>\n",
              "      <td>-0.021648</td>\n",
              "      <td>-0.135306</td>\n",
              "      <td>0.111917</td>\n",
              "      <td>-0.999275</td>\n",
              "      <td>0.419451</td>\n",
              "      <td>0.414028</td>\n",
              "      <td>0.212482</td>\n",
              "      <td>-0.152436</td>\n",
              "      <td>0.085479</td>\n",
              "      <td>0.092783</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>en</td>\n",
              "      <td>APR</td>\n",
              "      <td>0.215509</td>\n",
              "      <td>-0.325457</td>\n",
              "      <td>0.332228</td>\n",
              "      <td>-0.287824</td>\n",
              "      <td>-0.136689</td>\n",
              "      <td>0.383519</td>\n",
              "      <td>0.291183</td>\n",
              "      <td>0.286996</td>\n",
              "      <td>-0.481386</td>\n",
              "      <td>0.218290</td>\n",
              "      <td>-0.201273</td>\n",
              "      <td>-0.205439</td>\n",
              "      <td>-0.265380</td>\n",
              "      <td>-0.299966</td>\n",
              "      <td>0.223057</td>\n",
              "      <td>-0.247543</td>\n",
              "      <td>0.675796</td>\n",
              "      <td>0.117384</td>\n",
              "      <td>0.200475</td>\n",
              "      <td>-0.130950</td>\n",
              "      <td>-0.999962</td>\n",
              "      <td>-0.341156</td>\n",
              "      <td>-0.359581</td>\n",
              "      <td>-0.138069</td>\n",
              "      <td>-0.416840</td>\n",
              "      <td>0.228402</td>\n",
              "      <td>-0.272158</td>\n",
              "      <td>0.278628</td>\n",
              "      <td>0.188570</td>\n",
              "      <td>-0.246999</td>\n",
              "      <td>0.210601</td>\n",
              "      <td>-0.999960</td>\n",
              "      <td>0.755134</td>\n",
              "      <td>0.689256</td>\n",
              "      <td>0.309375</td>\n",
              "      <td>-0.144468</td>\n",
              "      <td>0.231340</td>\n",
              "      <td>0.231430</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>en</td>\n",
              "      <td>APR</td>\n",
              "      <td>0.026788</td>\n",
              "      <td>-0.305175</td>\n",
              "      <td>0.072571</td>\n",
              "      <td>-0.581912</td>\n",
              "      <td>-0.353657</td>\n",
              "      <td>-0.348442</td>\n",
              "      <td>0.470672</td>\n",
              "      <td>-0.131022</td>\n",
              "      <td>0.239081</td>\n",
              "      <td>-0.328728</td>\n",
              "      <td>-0.344556</td>\n",
              "      <td>0.109195</td>\n",
              "      <td>0.159580</td>\n",
              "      <td>0.189566</td>\n",
              "      <td>0.342923</td>\n",
              "      <td>0.367296</td>\n",
              "      <td>-0.619738</td>\n",
              "      <td>0.249904</td>\n",
              "      <td>0.488591</td>\n",
              "      <td>0.298604</td>\n",
              "      <td>-0.600034</td>\n",
              "      <td>-0.341328</td>\n",
              "      <td>0.367388</td>\n",
              "      <td>-0.358904</td>\n",
              "      <td>-0.097610</td>\n",
              "      <td>0.188682</td>\n",
              "      <td>-0.290164</td>\n",
              "      <td>0.363977</td>\n",
              "      <td>-0.022725</td>\n",
              "      <td>-0.348053</td>\n",
              "      <td>0.029906</td>\n",
              "      <td>-0.726957</td>\n",
              "      <td>0.912228</td>\n",
              "      <td>-0.427250</td>\n",
              "      <td>0.054324</td>\n",
              "      <td>-0.394523</td>\n",
              "      <td>-0.263104</td>\n",
              "      <td>-0.133449</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>en</td>\n",
              "      <td>APR</td>\n",
              "      <td>0.167107</td>\n",
              "      <td>-0.194416</td>\n",
              "      <td>0.234103</td>\n",
              "      <td>-0.311199</td>\n",
              "      <td>-0.171992</td>\n",
              "      <td>0.159504</td>\n",
              "      <td>0.265455</td>\n",
              "      <td>0.096494</td>\n",
              "      <td>-0.173541</td>\n",
              "      <td>0.024549</td>\n",
              "      <td>-0.192411</td>\n",
              "      <td>0.036744</td>\n",
              "      <td>-0.079506</td>\n",
              "      <td>-0.102444</td>\n",
              "      <td>0.089812</td>\n",
              "      <td>0.040732</td>\n",
              "      <td>0.248893</td>\n",
              "      <td>0.193850</td>\n",
              "      <td>0.305282</td>\n",
              "      <td>0.004850</td>\n",
              "      <td>-0.984261</td>\n",
              "      <td>-0.003436</td>\n",
              "      <td>-0.128723</td>\n",
              "      <td>-0.078641</td>\n",
              "      <td>-0.139610</td>\n",
              "      <td>0.246347</td>\n",
              "      <td>-0.198116</td>\n",
              "      <td>0.245280</td>\n",
              "      <td>0.044969</td>\n",
              "      <td>-0.251157</td>\n",
              "      <td>0.091292</td>\n",
              "      <td>-0.982581</td>\n",
              "      <td>0.727015</td>\n",
              "      <td>0.476094</td>\n",
              "      <td>0.220772</td>\n",
              "      <td>0.005005</td>\n",
              "      <td>0.019828</td>\n",
              "      <td>0.149508</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>en</td>\n",
              "      <td>APR</td>\n",
              "      <td>0.350445</td>\n",
              "      <td>-0.230253</td>\n",
              "      <td>0.319622</td>\n",
              "      <td>-0.219304</td>\n",
              "      <td>-0.079355</td>\n",
              "      <td>0.508322</td>\n",
              "      <td>0.284624</td>\n",
              "      <td>0.340958</td>\n",
              "      <td>-0.570853</td>\n",
              "      <td>0.349486</td>\n",
              "      <td>-0.063045</td>\n",
              "      <td>-0.229274</td>\n",
              "      <td>-0.319232</td>\n",
              "      <td>-0.275659</td>\n",
              "      <td>0.280474</td>\n",
              "      <td>-0.407663</td>\n",
              "      <td>0.854582</td>\n",
              "      <td>0.114386</td>\n",
              "      <td>0.167656</td>\n",
              "      <td>-0.375742</td>\n",
              "      <td>-0.999933</td>\n",
              "      <td>-0.292812</td>\n",
              "      <td>-0.528830</td>\n",
              "      <td>-0.177153</td>\n",
              "      <td>-0.574390</td>\n",
              "      <td>0.373710</td>\n",
              "      <td>-0.290632</td>\n",
              "      <td>0.249860</td>\n",
              "      <td>0.404556</td>\n",
              "      <td>-0.316472</td>\n",
              "      <td>0.168192</td>\n",
              "      <td>-0.999944</td>\n",
              "      <td>0.741588</td>\n",
              "      <td>0.788995</td>\n",
              "      <td>0.343340</td>\n",
              "      <td>-0.154618</td>\n",
              "      <td>0.263667</td>\n",
              "      <td>0.352792</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 6914 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "  0    1         2         3         4     ...  6909  6910  6911  6912  6913\n",
              "0   en  APR  0.214127 -0.255636  0.392288  ...   NaN   NaN   NaN   NaN   NaN\n",
              "1   en  APR  0.215509 -0.325457  0.332228  ...   NaN   NaN   NaN   NaN   NaN\n",
              "2   en  APR  0.026788 -0.305175  0.072571  ...   NaN   NaN   NaN   NaN   NaN\n",
              "3   en  APR  0.167107 -0.194416  0.234103  ...   NaN   NaN   NaN   NaN   NaN\n",
              "4   en  APR  0.350445 -0.230253  0.319622  ...   NaN   NaN   NaN   NaN   NaN\n",
              "\n",
              "[5 rows x 6914 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BynFklnEp78v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_flatten = df_flatten.rename(columns={0: 'language', 1: 'category'})"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w3432ny1p9k7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "outputId": "5aa16a31-26cb-49e2-9065-e1ebbbcc0900"
      },
      "source": [
        "df_flatten.head()"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>language</th>\n",
              "      <th>category</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>6874</th>\n",
              "      <th>6875</th>\n",
              "      <th>6876</th>\n",
              "      <th>6877</th>\n",
              "      <th>6878</th>\n",
              "      <th>6879</th>\n",
              "      <th>6880</th>\n",
              "      <th>6881</th>\n",
              "      <th>6882</th>\n",
              "      <th>6883</th>\n",
              "      <th>6884</th>\n",
              "      <th>6885</th>\n",
              "      <th>6886</th>\n",
              "      <th>6887</th>\n",
              "      <th>6888</th>\n",
              "      <th>6889</th>\n",
              "      <th>6890</th>\n",
              "      <th>6891</th>\n",
              "      <th>6892</th>\n",
              "      <th>6893</th>\n",
              "      <th>6894</th>\n",
              "      <th>6895</th>\n",
              "      <th>6896</th>\n",
              "      <th>6897</th>\n",
              "      <th>6898</th>\n",
              "      <th>6899</th>\n",
              "      <th>6900</th>\n",
              "      <th>6901</th>\n",
              "      <th>6902</th>\n",
              "      <th>6903</th>\n",
              "      <th>6904</th>\n",
              "      <th>6905</th>\n",
              "      <th>6906</th>\n",
              "      <th>6907</th>\n",
              "      <th>6908</th>\n",
              "      <th>6909</th>\n",
              "      <th>6910</th>\n",
              "      <th>6911</th>\n",
              "      <th>6912</th>\n",
              "      <th>6913</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>en</td>\n",
              "      <td>APR</td>\n",
              "      <td>0.214127</td>\n",
              "      <td>-0.255636</td>\n",
              "      <td>0.392288</td>\n",
              "      <td>-0.109920</td>\n",
              "      <td>-0.026097</td>\n",
              "      <td>0.148366</td>\n",
              "      <td>0.293664</td>\n",
              "      <td>0.275959</td>\n",
              "      <td>-0.319734</td>\n",
              "      <td>0.139019</td>\n",
              "      <td>-0.054376</td>\n",
              "      <td>0.000006</td>\n",
              "      <td>-0.180775</td>\n",
              "      <td>-0.144149</td>\n",
              "      <td>0.103221</td>\n",
              "      <td>-0.070089</td>\n",
              "      <td>0.368038</td>\n",
              "      <td>0.070929</td>\n",
              "      <td>0.201238</td>\n",
              "      <td>-0.079317</td>\n",
              "      <td>-0.999311</td>\n",
              "      <td>-0.197135</td>\n",
              "      <td>-0.162490</td>\n",
              "      <td>-0.111980</td>\n",
              "      <td>-0.295185</td>\n",
              "      <td>0.138431</td>\n",
              "      <td>-0.152204</td>\n",
              "      <td>0.292405</td>\n",
              "      <td>-0.021648</td>\n",
              "      <td>-0.135306</td>\n",
              "      <td>0.111917</td>\n",
              "      <td>-0.999275</td>\n",
              "      <td>0.419451</td>\n",
              "      <td>0.414028</td>\n",
              "      <td>0.212482</td>\n",
              "      <td>-0.152436</td>\n",
              "      <td>0.085479</td>\n",
              "      <td>0.092783</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>en</td>\n",
              "      <td>APR</td>\n",
              "      <td>0.215509</td>\n",
              "      <td>-0.325457</td>\n",
              "      <td>0.332228</td>\n",
              "      <td>-0.287824</td>\n",
              "      <td>-0.136689</td>\n",
              "      <td>0.383519</td>\n",
              "      <td>0.291183</td>\n",
              "      <td>0.286996</td>\n",
              "      <td>-0.481386</td>\n",
              "      <td>0.218290</td>\n",
              "      <td>-0.201273</td>\n",
              "      <td>-0.205439</td>\n",
              "      <td>-0.265380</td>\n",
              "      <td>-0.299966</td>\n",
              "      <td>0.223057</td>\n",
              "      <td>-0.247543</td>\n",
              "      <td>0.675796</td>\n",
              "      <td>0.117384</td>\n",
              "      <td>0.200475</td>\n",
              "      <td>-0.130950</td>\n",
              "      <td>-0.999962</td>\n",
              "      <td>-0.341156</td>\n",
              "      <td>-0.359581</td>\n",
              "      <td>-0.138069</td>\n",
              "      <td>-0.416840</td>\n",
              "      <td>0.228402</td>\n",
              "      <td>-0.272158</td>\n",
              "      <td>0.278628</td>\n",
              "      <td>0.188570</td>\n",
              "      <td>-0.246999</td>\n",
              "      <td>0.210601</td>\n",
              "      <td>-0.999960</td>\n",
              "      <td>0.755134</td>\n",
              "      <td>0.689256</td>\n",
              "      <td>0.309375</td>\n",
              "      <td>-0.144468</td>\n",
              "      <td>0.231340</td>\n",
              "      <td>0.231430</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>en</td>\n",
              "      <td>APR</td>\n",
              "      <td>0.026788</td>\n",
              "      <td>-0.305175</td>\n",
              "      <td>0.072571</td>\n",
              "      <td>-0.581912</td>\n",
              "      <td>-0.353657</td>\n",
              "      <td>-0.348442</td>\n",
              "      <td>0.470672</td>\n",
              "      <td>-0.131022</td>\n",
              "      <td>0.239081</td>\n",
              "      <td>-0.328728</td>\n",
              "      <td>-0.344556</td>\n",
              "      <td>0.109195</td>\n",
              "      <td>0.159580</td>\n",
              "      <td>0.189566</td>\n",
              "      <td>0.342923</td>\n",
              "      <td>0.367296</td>\n",
              "      <td>-0.619738</td>\n",
              "      <td>0.249904</td>\n",
              "      <td>0.488591</td>\n",
              "      <td>0.298604</td>\n",
              "      <td>-0.600034</td>\n",
              "      <td>-0.341328</td>\n",
              "      <td>0.367388</td>\n",
              "      <td>-0.358904</td>\n",
              "      <td>-0.097610</td>\n",
              "      <td>0.188682</td>\n",
              "      <td>-0.290164</td>\n",
              "      <td>0.363977</td>\n",
              "      <td>-0.022725</td>\n",
              "      <td>-0.348053</td>\n",
              "      <td>0.029906</td>\n",
              "      <td>-0.726957</td>\n",
              "      <td>0.912228</td>\n",
              "      <td>-0.427250</td>\n",
              "      <td>0.054324</td>\n",
              "      <td>-0.394523</td>\n",
              "      <td>-0.263104</td>\n",
              "      <td>-0.133449</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>en</td>\n",
              "      <td>APR</td>\n",
              "      <td>0.167107</td>\n",
              "      <td>-0.194416</td>\n",
              "      <td>0.234103</td>\n",
              "      <td>-0.311199</td>\n",
              "      <td>-0.171992</td>\n",
              "      <td>0.159504</td>\n",
              "      <td>0.265455</td>\n",
              "      <td>0.096494</td>\n",
              "      <td>-0.173541</td>\n",
              "      <td>0.024549</td>\n",
              "      <td>-0.192411</td>\n",
              "      <td>0.036744</td>\n",
              "      <td>-0.079506</td>\n",
              "      <td>-0.102444</td>\n",
              "      <td>0.089812</td>\n",
              "      <td>0.040732</td>\n",
              "      <td>0.248893</td>\n",
              "      <td>0.193850</td>\n",
              "      <td>0.305282</td>\n",
              "      <td>0.004850</td>\n",
              "      <td>-0.984261</td>\n",
              "      <td>-0.003436</td>\n",
              "      <td>-0.128723</td>\n",
              "      <td>-0.078641</td>\n",
              "      <td>-0.139610</td>\n",
              "      <td>0.246347</td>\n",
              "      <td>-0.198116</td>\n",
              "      <td>0.245280</td>\n",
              "      <td>0.044969</td>\n",
              "      <td>-0.251157</td>\n",
              "      <td>0.091292</td>\n",
              "      <td>-0.982581</td>\n",
              "      <td>0.727015</td>\n",
              "      <td>0.476094</td>\n",
              "      <td>0.220772</td>\n",
              "      <td>0.005005</td>\n",
              "      <td>0.019828</td>\n",
              "      <td>0.149508</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>en</td>\n",
              "      <td>APR</td>\n",
              "      <td>0.350445</td>\n",
              "      <td>-0.230253</td>\n",
              "      <td>0.319622</td>\n",
              "      <td>-0.219304</td>\n",
              "      <td>-0.079355</td>\n",
              "      <td>0.508322</td>\n",
              "      <td>0.284624</td>\n",
              "      <td>0.340958</td>\n",
              "      <td>-0.570853</td>\n",
              "      <td>0.349486</td>\n",
              "      <td>-0.063045</td>\n",
              "      <td>-0.229274</td>\n",
              "      <td>-0.319232</td>\n",
              "      <td>-0.275659</td>\n",
              "      <td>0.280474</td>\n",
              "      <td>-0.407663</td>\n",
              "      <td>0.854582</td>\n",
              "      <td>0.114386</td>\n",
              "      <td>0.167656</td>\n",
              "      <td>-0.375742</td>\n",
              "      <td>-0.999933</td>\n",
              "      <td>-0.292812</td>\n",
              "      <td>-0.528830</td>\n",
              "      <td>-0.177153</td>\n",
              "      <td>-0.574390</td>\n",
              "      <td>0.373710</td>\n",
              "      <td>-0.290632</td>\n",
              "      <td>0.249860</td>\n",
              "      <td>0.404556</td>\n",
              "      <td>-0.316472</td>\n",
              "      <td>0.168192</td>\n",
              "      <td>-0.999944</td>\n",
              "      <td>0.741588</td>\n",
              "      <td>0.788995</td>\n",
              "      <td>0.343340</td>\n",
              "      <td>-0.154618</td>\n",
              "      <td>0.263667</td>\n",
              "      <td>0.352792</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 6914 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "  language category         2         3         4  ...  6909  6910  6911  6912  6913\n",
              "0       en      APR  0.214127 -0.255636  0.392288  ...   NaN   NaN   NaN   NaN   NaN\n",
              "1       en      APR  0.215509 -0.325457  0.332228  ...   NaN   NaN   NaN   NaN   NaN\n",
              "2       en      APR  0.026788 -0.305175  0.072571  ...   NaN   NaN   NaN   NaN   NaN\n",
              "3       en      APR  0.167107 -0.194416  0.234103  ...   NaN   NaN   NaN   NaN   NaN\n",
              "4       en      APR  0.350445 -0.230253  0.319622  ...   NaN   NaN   NaN   NaN   NaN\n",
              "\n",
              "[5 rows x 6914 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Przfb-L5p_jt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_flatten.to_csv('/content/drive/My Drive/ea_embeddings_bert_flatten_good.csv', index=False, encoding='utf-8') "
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKU-ZBkdtIrY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
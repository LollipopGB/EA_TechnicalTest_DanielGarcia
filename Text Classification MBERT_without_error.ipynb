{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1 - Text classification\n",
    "\n",
    "The results in the this notebook are not \"expected\". This is because the size of the data was extremely reduced to compute all the batches fed to MBERT to generate the embeddings. With a time and computational resources, this approach would work better. But the aim of this notebook is to show another viable approach to address the same task.\n",
    "\n",
    "### 1) Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import os\n",
    "import sys\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Read the csv\n",
    "\n",
    "This csv is the output from the notebook run in Google Colab.\n",
    "\n",
    "The word embedding is flatten, generating as many columns as the length of the vector (512)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_f= pd.read_csv('ea_embeddings_bert_flatten_good.csv', sep=',', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>category</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>6904</th>\n",
       "      <th>6905</th>\n",
       "      <th>6906</th>\n",
       "      <th>6907</th>\n",
       "      <th>6908</th>\n",
       "      <th>6909</th>\n",
       "      <th>6910</th>\n",
       "      <th>6911</th>\n",
       "      <th>6912</th>\n",
       "      <th>6913</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>en</td>\n",
       "      <td>APR</td>\n",
       "      <td>0.214127</td>\n",
       "      <td>-0.255636</td>\n",
       "      <td>0.392288</td>\n",
       "      <td>-0.109920</td>\n",
       "      <td>-0.026097</td>\n",
       "      <td>0.148366</td>\n",
       "      <td>0.293664</td>\n",
       "      <td>0.275959</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>en</td>\n",
       "      <td>APR</td>\n",
       "      <td>0.215509</td>\n",
       "      <td>-0.325457</td>\n",
       "      <td>0.332228</td>\n",
       "      <td>-0.287824</td>\n",
       "      <td>-0.136689</td>\n",
       "      <td>0.383519</td>\n",
       "      <td>0.291183</td>\n",
       "      <td>0.286996</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>en</td>\n",
       "      <td>APR</td>\n",
       "      <td>0.026788</td>\n",
       "      <td>-0.305175</td>\n",
       "      <td>0.072571</td>\n",
       "      <td>-0.581912</td>\n",
       "      <td>-0.353657</td>\n",
       "      <td>-0.348442</td>\n",
       "      <td>0.470672</td>\n",
       "      <td>-0.131022</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>en</td>\n",
       "      <td>APR</td>\n",
       "      <td>0.167107</td>\n",
       "      <td>-0.194416</td>\n",
       "      <td>0.234103</td>\n",
       "      <td>-0.311199</td>\n",
       "      <td>-0.171992</td>\n",
       "      <td>0.159504</td>\n",
       "      <td>0.265455</td>\n",
       "      <td>0.096494</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>en</td>\n",
       "      <td>APR</td>\n",
       "      <td>0.350445</td>\n",
       "      <td>-0.230253</td>\n",
       "      <td>0.319622</td>\n",
       "      <td>-0.219304</td>\n",
       "      <td>-0.079355</td>\n",
       "      <td>0.508322</td>\n",
       "      <td>0.284624</td>\n",
       "      <td>0.340958</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 6914 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  language category         2         3         4         5         6  \\\n",
       "0       en      APR  0.214127 -0.255636  0.392288 -0.109920 -0.026097   \n",
       "1       en      APR  0.215509 -0.325457  0.332228 -0.287824 -0.136689   \n",
       "2       en      APR  0.026788 -0.305175  0.072571 -0.581912 -0.353657   \n",
       "3       en      APR  0.167107 -0.194416  0.234103 -0.311199 -0.171992   \n",
       "4       en      APR  0.350445 -0.230253  0.319622 -0.219304 -0.079355   \n",
       "\n",
       "          7         8         9  ...  6904  6905  6906  6907  6908  6909  \\\n",
       "0  0.148366  0.293664  0.275959  ...   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "1  0.383519  0.291183  0.286996  ...   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "2 -0.348442  0.470672 -0.131022  ...   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "3  0.159504  0.265455  0.096494  ...   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "4  0.508322  0.284624  0.340958  ...   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "\n",
       "   6910  6911  6912  6913  \n",
       "0   NaN   NaN   NaN   NaN  \n",
       "1   NaN   NaN   NaN   NaN  \n",
       "2   NaN   NaN   NaN   NaN  \n",
       "3   NaN   NaN   NaN   NaN  \n",
       "4   NaN   NaN   NaN   NaN  \n",
       "\n",
       "[5 rows x 6914 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_f.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One hot encoding of categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use pd.concat to join the new columns with your original dataframe\n",
    "df_f = pd.concat([df_f,pd.get_dummies(df_f['language'], prefix='language')],axis=1)\n",
    "\n",
    "# now drop the original 'country' column (you don't need it anymore)\n",
    "df_f.drop(['language'],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>6907</th>\n",
       "      <th>6908</th>\n",
       "      <th>6909</th>\n",
       "      <th>6910</th>\n",
       "      <th>6911</th>\n",
       "      <th>6912</th>\n",
       "      <th>6913</th>\n",
       "      <th>language_en</th>\n",
       "      <th>language_es</th>\n",
       "      <th>language_fr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>APR</td>\n",
       "      <td>0.214127</td>\n",
       "      <td>-0.255636</td>\n",
       "      <td>0.392288</td>\n",
       "      <td>-0.109920</td>\n",
       "      <td>-0.026097</td>\n",
       "      <td>0.148366</td>\n",
       "      <td>0.293664</td>\n",
       "      <td>0.275959</td>\n",
       "      <td>-0.319734</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>APR</td>\n",
       "      <td>0.215509</td>\n",
       "      <td>-0.325457</td>\n",
       "      <td>0.332228</td>\n",
       "      <td>-0.287824</td>\n",
       "      <td>-0.136689</td>\n",
       "      <td>0.383519</td>\n",
       "      <td>0.291183</td>\n",
       "      <td>0.286996</td>\n",
       "      <td>-0.481386</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>APR</td>\n",
       "      <td>0.026788</td>\n",
       "      <td>-0.305175</td>\n",
       "      <td>0.072571</td>\n",
       "      <td>-0.581912</td>\n",
       "      <td>-0.353657</td>\n",
       "      <td>-0.348442</td>\n",
       "      <td>0.470672</td>\n",
       "      <td>-0.131022</td>\n",
       "      <td>0.239081</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>APR</td>\n",
       "      <td>0.167107</td>\n",
       "      <td>-0.194416</td>\n",
       "      <td>0.234103</td>\n",
       "      <td>-0.311199</td>\n",
       "      <td>-0.171992</td>\n",
       "      <td>0.159504</td>\n",
       "      <td>0.265455</td>\n",
       "      <td>0.096494</td>\n",
       "      <td>-0.173541</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>APR</td>\n",
       "      <td>0.350445</td>\n",
       "      <td>-0.230253</td>\n",
       "      <td>0.319622</td>\n",
       "      <td>-0.219304</td>\n",
       "      <td>-0.079355</td>\n",
       "      <td>0.508322</td>\n",
       "      <td>0.284624</td>\n",
       "      <td>0.340958</td>\n",
       "      <td>-0.570853</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 6916 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  category         2         3         4         5         6         7  \\\n",
       "0      APR  0.214127 -0.255636  0.392288 -0.109920 -0.026097  0.148366   \n",
       "1      APR  0.215509 -0.325457  0.332228 -0.287824 -0.136689  0.383519   \n",
       "2      APR  0.026788 -0.305175  0.072571 -0.581912 -0.353657 -0.348442   \n",
       "3      APR  0.167107 -0.194416  0.234103 -0.311199 -0.171992  0.159504   \n",
       "4      APR  0.350445 -0.230253  0.319622 -0.219304 -0.079355  0.508322   \n",
       "\n",
       "          8         9        10  ...  6907  6908  6909  6910  6911  6912  \\\n",
       "0  0.293664  0.275959 -0.319734  ...   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "1  0.291183  0.286996 -0.481386  ...   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "2  0.470672 -0.131022  0.239081  ...   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "3  0.265455  0.096494 -0.173541  ...   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "4  0.284624  0.340958 -0.570853  ...   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "\n",
       "   6913  language_en  language_es  language_fr  \n",
       "0   NaN            1            0            0  \n",
       "1   NaN            1            0            0  \n",
       "2   NaN            1            0            0  \n",
       "3   NaN            1            0            0  \n",
       "4   NaN            1            0            0  \n",
       "\n",
       "[5 rows x 6916 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_f.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_f=df_f.dropna(axis=1,how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>763</th>\n",
       "      <th>764</th>\n",
       "      <th>765</th>\n",
       "      <th>766</th>\n",
       "      <th>767</th>\n",
       "      <th>768</th>\n",
       "      <th>769</th>\n",
       "      <th>language_en</th>\n",
       "      <th>language_es</th>\n",
       "      <th>language_fr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>APR</td>\n",
       "      <td>0.214127</td>\n",
       "      <td>-0.255636</td>\n",
       "      <td>0.392288</td>\n",
       "      <td>-0.109920</td>\n",
       "      <td>-0.026097</td>\n",
       "      <td>0.148366</td>\n",
       "      <td>0.293664</td>\n",
       "      <td>0.275959</td>\n",
       "      <td>-0.319734</td>\n",
       "      <td>...</td>\n",
       "      <td>0.760154</td>\n",
       "      <td>0.236110</td>\n",
       "      <td>0.069117</td>\n",
       "      <td>0.286525</td>\n",
       "      <td>-0.237154</td>\n",
       "      <td>0.210623</td>\n",
       "      <td>0.166840</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>APR</td>\n",
       "      <td>0.215509</td>\n",
       "      <td>-0.325457</td>\n",
       "      <td>0.332228</td>\n",
       "      <td>-0.287824</td>\n",
       "      <td>-0.136689</td>\n",
       "      <td>0.383519</td>\n",
       "      <td>0.291183</td>\n",
       "      <td>0.286996</td>\n",
       "      <td>-0.481386</td>\n",
       "      <td>...</td>\n",
       "      <td>0.915986</td>\n",
       "      <td>0.330213</td>\n",
       "      <td>0.350417</td>\n",
       "      <td>0.210346</td>\n",
       "      <td>-0.446477</td>\n",
       "      <td>0.363072</td>\n",
       "      <td>0.322220</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>APR</td>\n",
       "      <td>0.026788</td>\n",
       "      <td>-0.305175</td>\n",
       "      <td>0.072571</td>\n",
       "      <td>-0.581912</td>\n",
       "      <td>-0.353657</td>\n",
       "      <td>-0.348442</td>\n",
       "      <td>0.470672</td>\n",
       "      <td>-0.131022</td>\n",
       "      <td>0.239081</td>\n",
       "      <td>...</td>\n",
       "      <td>0.990188</td>\n",
       "      <td>0.018095</td>\n",
       "      <td>-0.012594</td>\n",
       "      <td>-0.209171</td>\n",
       "      <td>-0.475615</td>\n",
       "      <td>0.182417</td>\n",
       "      <td>0.382166</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>APR</td>\n",
       "      <td>0.167107</td>\n",
       "      <td>-0.194416</td>\n",
       "      <td>0.234103</td>\n",
       "      <td>-0.311199</td>\n",
       "      <td>-0.171992</td>\n",
       "      <td>0.159504</td>\n",
       "      <td>0.265455</td>\n",
       "      <td>0.096494</td>\n",
       "      <td>-0.173541</td>\n",
       "      <td>...</td>\n",
       "      <td>0.918594</td>\n",
       "      <td>0.261794</td>\n",
       "      <td>0.163606</td>\n",
       "      <td>0.017038</td>\n",
       "      <td>-0.231260</td>\n",
       "      <td>0.300026</td>\n",
       "      <td>0.318531</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>APR</td>\n",
       "      <td>0.350445</td>\n",
       "      <td>-0.230253</td>\n",
       "      <td>0.319622</td>\n",
       "      <td>-0.219304</td>\n",
       "      <td>-0.079355</td>\n",
       "      <td>0.508322</td>\n",
       "      <td>0.284624</td>\n",
       "      <td>0.340958</td>\n",
       "      <td>-0.570853</td>\n",
       "      <td>...</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.363611</td>\n",
       "      <td>0.347100</td>\n",
       "      <td>0.305120</td>\n",
       "      <td>-0.490583</td>\n",
       "      <td>0.399251</td>\n",
       "      <td>0.338498</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 772 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  category         2         3         4         5         6         7  \\\n",
       "0      APR  0.214127 -0.255636  0.392288 -0.109920 -0.026097  0.148366   \n",
       "1      APR  0.215509 -0.325457  0.332228 -0.287824 -0.136689  0.383519   \n",
       "2      APR  0.026788 -0.305175  0.072571 -0.581912 -0.353657 -0.348442   \n",
       "3      APR  0.167107 -0.194416  0.234103 -0.311199 -0.171992  0.159504   \n",
       "4      APR  0.350445 -0.230253  0.319622 -0.219304 -0.079355  0.508322   \n",
       "\n",
       "          8         9        10  ...       763       764       765       766  \\\n",
       "0  0.293664  0.275959 -0.319734  ...  0.760154  0.236110  0.069117  0.286525   \n",
       "1  0.291183  0.286996 -0.481386  ...  0.915986  0.330213  0.350417  0.210346   \n",
       "2  0.470672 -0.131022  0.239081  ...  0.990188  0.018095 -0.012594 -0.209171   \n",
       "3  0.265455  0.096494 -0.173541  ...  0.918594  0.261794  0.163606  0.017038   \n",
       "4  0.284624  0.340958 -0.570853  ...  0.939394  0.363611  0.347100  0.305120   \n",
       "\n",
       "        767       768       769  language_en  language_es  language_fr  \n",
       "0 -0.237154  0.210623  0.166840            1            0            0  \n",
       "1 -0.446477  0.363072  0.322220            1            0            0  \n",
       "2 -0.475615  0.182417  0.382166            1            0            0  \n",
       "3 -0.231260  0.300026  0.318531            1            0            0  \n",
       "4 -0.490583  0.399251  0.338498            1            0            0  \n",
       "\n",
       "[5 rows x 772 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_f.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We separate the feature vector and the label in two different dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_label = df_f['category']\n",
    "df_features = df_f.drop(columns=['category'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split the dataset into training (90%) and test (10%). With the stratify function, it is ensure that there is a good proportion of the 4 labels in both sets. The percetanges are changed because now we have less data (we trimmed it to reduce the computation times)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_features, df_label, stratify=df_label, test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We train a classifier an we are going to start with a very basic as Logistic Regression model, because sometimes the simpler the better. There are also other reasons for that, for example, not all the languages have text in all categories, so it is easy to discard a language in some categories, reducing the problem to a kind of \"binary\" classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9961783439490446\n",
      "[[214   0   0   0]\n",
      " [  0  21   0   0]\n",
      " [  2   0  95   0]\n",
      " [  1   0   0 452]]\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "              APR       0.99      1.00      0.99       214\n",
      "Conference_papers       1.00      1.00      1.00        21\n",
      "            PAN11       1.00      0.98      0.99        97\n",
      "        Wikipedia       1.00      1.00      1.00       453\n",
      "\n",
      "         accuracy                           1.00       785\n",
      "        macro avg       1.00      0.99      1.00       785\n",
      "     weighted avg       1.00      1.00      1.00       785\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\tf2_gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "score = lr.score(X_test, y_test)\n",
    "print(score)\n",
    "\n",
    "cm = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "\n",
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7273            Wikipedia\n",
      "7182            Wikipedia\n",
      "4424            Wikipedia\n",
      "1130                  APR\n",
      "6747            Wikipedia\n",
      "5293            Wikipedia\n",
      "6141            Wikipedia\n",
      "2328    Conference_papers\n",
      "1057                  APR\n",
      "3567            Wikipedia\n",
      "Name: category, dtype: object\n",
      "['Wikipedia' 'Wikipedia' 'Wikipedia' 'APR' 'Wikipedia' 'Wikipedia'\n",
      " 'Wikipedia' 'Conference_papers' 'APR' 'Wikipedia']\n"
     ]
    }
   ],
   "source": [
    "print(y_test[0:10])\n",
    "print(y_pred[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(9,9))\n",
    "plt.imshow(cm, interpolation='nearest', cmap='Pastel1')\n",
    "plt.title('Confusion matrix', size = 15)\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(4)\n",
    "plt.xticks(tick_marks, [\"APR\", \"CP\", \"PAN11\", \"Wikipedia\"], rotation=45, size = 10)\n",
    "plt.yticks(tick_marks, [\"APR\", \"CP\", \"PAN11\", \"Wikipedia\"], size = 10)\n",
    "plt.tight_layout()\n",
    "plt.ylabel('Actual label', size = 15)\n",
    "plt.xlabel('Predicted label', size = 15)\n",
    "width, height = cm.shape\n",
    "for x in range(width):\n",
    "    for y in range(height):\n",
    "        plt.annotate(str(cm[x][y]), xy=(y, x), \n",
    "        horizontalalignment='center',\n",
    "        verticalalignment='center')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resuts are not good. Wikipedia is the only label classified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9910828025477707\n",
      "[[212   0   2   0]\n",
      " [  0  20   0   1]\n",
      " [  2   0  95   0]\n",
      " [  1   0   1 451]]\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "              APR       0.99      0.99      0.99       214\n",
      "Conference_papers       1.00      0.95      0.98        21\n",
      "            PAN11       0.97      0.98      0.97        97\n",
      "        Wikipedia       1.00      1.00      1.00       453\n",
      "\n",
      "         accuracy                           0.99       785\n",
      "        macro avg       0.99      0.98      0.98       785\n",
      "     weighted avg       0.99      0.99      0.99       785\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm_cl = svm.SVC(kernel='linear')\n",
    "svm_cl.fit(X_train, y_train)\n",
    "y_pred = svm_cl.predict(X_test)\n",
    "\n",
    "score = svm_cl.score(X_test, y_test)\n",
    "print(score)\n",
    "\n",
    "cm = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "\n",
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are the same with a more complex model, lets try to apply Cross Validation to separate the data split influence in the behaviour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5,random_state=42,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\tf2_gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "D:\\Anaconda\\envs\\tf2_gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "D:\\Anaconda\\envs\\tf2_gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "D:\\Anaconda\\envs\\tf2_gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "D:\\Anaconda\\envs\\tf2_gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "accuracies = []\n",
    "\n",
    "for train_index, test_index in kf.split(df_label):\n",
    "\n",
    "    data_train   = df_features.loc[train_index]\n",
    "    target_train = df_label.loc[train_index]\n",
    "\n",
    "    data_test    = df_features.loc[test_index]\n",
    "    target_test  = df_label.loc[test_index]\n",
    "\n",
    "    # if needed, do preprocessing here\n",
    "\n",
    "    clf = LogisticRegression()\n",
    "    clf.fit(data_train,target_train)\n",
    "\n",
    "    preds = clf.predict(data_test)\n",
    "\n",
    "    # accuracy for the current fold only    \n",
    "    accuracy = metrics.accuracy_score(target_test,preds)\n",
    "\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "# this is the average accuracy over all folds\n",
    "average_accuracy = np.mean(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9904458598726115, 0.9859872611464968, 0.9834289356277884, 0.9904397705544933, 0.9904397705544933]\n",
      "0.9881483195511767\n"
     ]
    }
   ],
   "source": [
    "print(accuracies)\n",
    "print(average_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the end, the results are similar. It happens because the documents were trimmed too much, and the number of documents was reduced. It was done just to show the viability of another technique to solve the problem, but the lack of time and computational resources pushed to reduce the data to deliver this approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
